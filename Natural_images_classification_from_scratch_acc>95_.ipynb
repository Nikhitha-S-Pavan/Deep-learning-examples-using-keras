{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_images_classification_from_scratch_acc>95%.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNrRw2Pr5gDaHlDIN2VPqLV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhitha-S-Pavan/Deep-learning-examples-using-keras/blob/main/Natural_images_classification_from_scratch_acc%3E95_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhwNUsvklpn8"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FnEHpEbl6Nt"
      },
      "source": [
        "# !unzip -uq \"/content/drive/My Drive/kaggle_dataset/natural_images.zip\" -d \"/content/drive/My Drive/kaggle_dataset/natural_images/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3d1tQgTmjDy"
      },
      "source": [
        "train_path = \"/content/drive/My Drive/kaggle_dataset/natural_images/data/natural_images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbO_H4rFmjTS"
      },
      "source": [
        "import cv2 \r\n",
        "im = cv2.imread(\"/content/drive/My Drive/kaggle_dataset/natural_images/resized/person/person_0001.jpg\")\r\n",
        "im.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JQsUiR1rQEH"
      },
      "source": [
        "# Create directories and subdirectories to save resized images\r\n",
        "import glob\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "\r\n",
        "for dir in glob.glob(\"/content/drive/My Drive/kaggle_dataset/natural_images/data/natural_images/*/*\"):\r\n",
        "  split= dir.split(\"/\")\r\n",
        "  path_folder = os.path.join(\"/content/drive/My Drive/kaggle_dataset/natural_images/resized/\",split[8])\r\n",
        "  if os.path.exists(path_folder):\r\n",
        "    continue\r\n",
        "  else:\r\n",
        "    os.makedirs(path_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgU1nE3QstTZ"
      },
      "source": [
        "\"\"\"# Resize training images of 'n' classes\r\n",
        "labels = [\"car\",\"motorbike\",\"flower\",\"fruit\",\"person\",\"cat\",\"dog\",\"airplane\"]\r\n",
        "resize_path_train = \"/content/drive/My Drive/kaggle_dataset/natural_images/resized/\"  \r\n",
        "for idx, value in enumerate(labels):\r\n",
        "    for im in glob.glob(os.path.join(\"/content/drive/My Drive/kaggle_dataset/natural_images/data/natural_images\",value ,'*')):\r\n",
        "      img  = cv2.imread(im)\r\n",
        "      width = 300\r\n",
        "      height = 300\r\n",
        "      dim = (width, height)\r\n",
        "      # resize image\r\n",
        "      resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\r\n",
        "      cv2.imwrite(os.path.join(resize_path_train, str(i), im.split(\"/\")[-1]), resized)\r\n",
        "      print(os.path.join(resize_path_train, value, im.split(\"/\")[-1]))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU1hnq8PmjWN"
      },
      "source": [
        "# Convolutional Neural Network\r\n",
        "\r\n",
        "# Importing the libraries\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQislnxWmja_"
      },
      "source": [
        "# Part 1 - Data Preprocessing\r\n",
        "\r\n",
        "# Preprocessing the Training set\r\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
        "                                   zoom_range = 0.2,\r\n",
        "                                   validation_split=0.2,\r\n",
        "                                   horizontal_flip = True)\r\n",
        "\r\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/kaggle_dataset/natural_images/data/natural_images/',\r\n",
        "                                                 target_size = (224,224),\r\n",
        "                                                 batch_size =32,\r\n",
        "                                                 class_mode = 'categorical',\r\n",
        "                                                 subset=\"training\")\r\n",
        "\r\n",
        "\r\n",
        "test_set = train_datagen.flow_from_directory('/content/drive/My Drive/kaggle_dataset/natural_images/data/natural_images/',\r\n",
        "                                            target_size = (224,224),\r\n",
        "                                            batch_size = 32,\r\n",
        "                                            class_mode = 'categorical',\r\n",
        "                                            subset=\"validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll1f9kvamjcx"
      },
      "source": [
        "# Part 2 - Building the CNN\r\n",
        "\r\n",
        "# Initialising the CNN\r\n",
        "cnn = tf.keras.models.Sequential()\r\n",
        "\r\n",
        "# Step 1 - Convolution\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128,padding=\"same\",kernel_size=3, activation='relu', input_shape=[224,224, 3]))\r\n",
        "\r\n",
        "# Step 2 - Pooling\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
        "\r\n",
        "# Adding a second convolutional layer\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,padding='same',kernel_size=3, activation='relu'))\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
        "\r\n",
        "# Adding a third convolutional layer\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=16,padding='same',kernel_size=3, activation='relu'))\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
        "\r\n",
        "# Step 3 - Flattening\r\n",
        "cnn.add(tf.keras.layers.Flatten())\r\n",
        "\r\n",
        "# Step 4 - Full Connection\r\n",
        "cnn.add(tf.keras.layers.Dense(256, activation='relu'))\r\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\r\n",
        "\r\n",
        "# Step 5 - Output Layer\r\n",
        "cnn.add(tf.keras.layers.Dense(units=8, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG3BwfqrZyYe"
      },
      "source": [
        "# Part 3 - Training the CNN\r\n",
        "\r\n",
        "# Compiling the CNN\r\n",
        "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWS0uj7HZzn_"
      },
      "source": [
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZrDYQkImjf1"
      },
      "source": [
        "history=cnn.fit_generator(\r\n",
        "    training_set,\r\n",
        "    epochs = 20,\r\n",
        "    validation_data = test_set,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF0BhkT9DogB"
      },
      "source": [
        "model.save(\"/content/drive/My Drive/kaggle_dataset/natural_images/data/natural_images_cnn.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC5pmpwKLToT"
      },
      "source": [
        "\"\"\"class myCallback(tf.keras.callbacks.Callback):\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if(logs.get('accuracy')>0.85):\r\n",
        "            print(\"\\nReached >85% accuracy so cancelling training!\")\r\n",
        "            self.model.stop_training = True\r\n",
        "        \r\n",
        "callbacks = myCallback()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozihGNcn67ut"
      },
      "source": [
        "from keras.preprocessing.image import load_img\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "# load and prepare the image\r\n",
        "def load_image(filename):\r\n",
        "  \r\n",
        "\t# load the image\r\n",
        "\timg = load_img(filename, target_size=(128,128))\r\n",
        "\t# convert to array\r\n",
        "\timg = img_to_array(img)\r\n",
        "\t# reshape into a single sample with 3 channels\r\n",
        "\timg = img.reshape(1, 128,128, 3)\r\n",
        "\t# center pixel data\r\n",
        "\timg = img.astype('float32')\r\n",
        "\timg = img - [123.68, 116.779, 103.939]\r\n",
        "\treturn img\r\n",
        " \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oe2qPUo7qKW"
      },
      "source": [
        "# load an image and predict the class\r\n",
        "def run_example():\r\n",
        "\t# load the image\r\n",
        "\timg = load_image('/content/drive/My Drive/kaggle_dataset/natural_images/resized/airplane/airplane_0000.jpg')\r\n",
        "\t# load model\r\n",
        "\tmodel = load_model('/content/drive/My Drive/kaggle_dataset/natural_images/data/natural_images_cnn.h5')\r\n",
        "\t# predict the class\r\n",
        "\tresult = model.predict(img)\r\n",
        "\tprint(result[0])\r\n",
        "  \r\n",
        " \r\n",
        "# entry point, run the example\r\n",
        "run_example()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}