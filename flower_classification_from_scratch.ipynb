{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower_classification_from_scratch.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRY4p9giXqlJSXYZWWB5G1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhitha-S-Pavan/Deep-learning-examples-using-keras/blob/main/flower_classification_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agfb_OTjyfel"
      },
      "source": [
        "# Code to read csv file into Colaboratory:\r\n",
        "!pip install -U -q PyDrive\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "# Authenticate and create the PyDrive client.\r\n",
        "auth.authenticate_user()\r\n",
        "gauth = GoogleAuth()\r\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czhEMxN3y_zd"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88uSlZujzAD7"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/kaggle_dataset/flower_data.zip\" -d \"/content/drive/My Drive/kaggle_dataset/flower_data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGO3zEHozAIK"
      },
      "source": [
        "train_path = \"/content/drive/My Drive/kaggle_dataset/flower_data/flower_data/train\"\r\n",
        "test_path = \"/content/drive/My Drive/kaggle_dataset/flower_data/flower_data/valid\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf5LXwpyzALP"
      },
      "source": [
        "import cv2 \r\n",
        "im = cv2.imread(\"/content/drive/My Drive/kaggle_dataset/flower_data/flower_data/train/1/image_06744.jpg\")\r\n",
        "im.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvpG7gLsBurC"
      },
      "source": [
        "# Create directories and subdirectories to save resized images\r\n",
        "import glob\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "\r\n",
        "for dir in glob.glob(\"/content/drive/My Drive/kaggle_dataset/flower_data/flower_data/*/*\"):\r\n",
        "  split= dir.split(\"/\")\r\n",
        "  path_folder = os.path.join(\"/content/drive/My Drive/kaggle_dataset/flower_data/resized/\",split[7], split[8])\r\n",
        "  if os.path.exists(path_folder):\r\n",
        "    print(path_folder + \" exists\")\r\n",
        "  else:\r\n",
        "    os.makedirs(path_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CM2-p28G6gz"
      },
      "source": [
        "# Resize training images of 'n' classes\r\n",
        "resize_path_train = \"/content/drive/My Drive/kaggle_dataset/flower_data/resized/train/\"  \r\n",
        "for i in range(0, 103):\r\n",
        "    for im in glob.glob(os.path.join(\"/content/drive/My Drive/kaggle_dataset/flower_data/flower_data/train\",str(i),'*')):\r\n",
        "      img  = cv2.imread(im)\r\n",
        "      width = 300\r\n",
        "      height = 300\r\n",
        "      dim = (width, height)\r\n",
        "      # resize image\r\n",
        "      resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\r\n",
        "      cv2.imwrite(os.path.join(resize_path_train, str(i), im.split(\"/\")[-1]), resized)\r\n",
        "      print(os.path.join(resize_path_train, str(i), im.split(\"/\")[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BERH_Dt-H9oT"
      },
      "source": [
        "# Resize testing images of 'n' classes\r\n",
        "resize_path_test = \"/content/drive/My Drive/kaggle_dataset/flower_data/resized/valid/\"\r\n",
        "for i in range(0, 103):\r\n",
        "  for im in glob.glob(os.path.join(\"/content/drive/My Drive/kaggle_dataset/flower_data/flower_data/valid\",str(i),'*')):\r\n",
        "    img  = cv2.imread(im)\r\n",
        "    width = 300\r\n",
        "    height = 300\r\n",
        "    dim = (width, height)\r\n",
        "    # resize image\r\n",
        "    resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\r\n",
        "    cv2.imwrite(os.path.join(resize_path_test, str(i), im.split(\"/\")[-1]), resized)\r\n",
        "    print(os.path.join(resize_path_test, str(i), im.split(\"/\")[-1]))\r\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeAxRcch_-VK"
      },
      "source": [
        "# Convolutional Neural Network\r\n",
        "\r\n",
        "# Importing the libraries\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5TSxxFT_-YS"
      },
      "source": [
        "# Part 1 - Data Preprocessing\r\n",
        "\r\n",
        "# Preprocessing the Training set\r\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
        "                                   zoom_range = 0.2,\r\n",
        "                                   horizontal_flip = True)\r\n",
        "\r\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/kaggle_dataset/flower_data/resized/train',\r\n",
        "                                                 target_size = (224,224),\r\n",
        "                                                 batch_size = 8,\r\n",
        "                                                 class_mode = 'categorical')\r\n",
        "\r\n",
        "# Preprocessing the Test set\r\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/kaggle_dataset/flower_data/resized/valid/',\r\n",
        "                                            target_size = (224,224),\r\n",
        "                                            batch_size = 8,\r\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRkaDGse_-a9"
      },
      "source": [
        "# Part 2 - Building the CNN\r\n",
        "\r\n",
        "# Initialising the CNN\r\n",
        "cnn = tf.keras.models.Sequential()\r\n",
        "\r\n",
        "# Step 1 - Convolution\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', input_shape=[224,224, 3]))\r\n",
        "\r\n",
        "# Step 2 - Pooling\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
        "\r\n",
        "# Adding a second convolutional layer\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
        "\r\n",
        "# Adding a third convolutional layer\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
        "\r\n",
        "# Adding a third convolutional layer\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
        "\r\n",
        "# Step 3 - Flattening\r\n",
        "cnn.add(tf.keras.layers.Flatten())\r\n",
        "\r\n",
        "# Step 4 - Full Connection\r\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\r\n",
        "\r\n",
        "# Step 5 - Output Layer\r\n",
        "cnn.add(tf.keras.layers.Dense(units=102, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1xHqXiF_-dS"
      },
      "source": [
        "# Part 3 - Training the CNN\r\n",
        "\r\n",
        "# Compiling the CNN\r\n",
        "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU3wqKq8_-fB"
      },
      "source": [
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPd1Em2B_-hn"
      },
      "source": [
        "# fit the model\r\n",
        "# Run the cell. It will take some time to execute\r\n",
        "r = cnn.fit_generator(\r\n",
        "  training_set,\r\n",
        "  validation_data=test_set,\r\n",
        "  epochs=50,\r\n",
        "\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr_rIQHq_-lJ"
      },
      "source": [
        "cnn.save(\"flowe_classification_model.h5\")\r\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}