{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_boston_housing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vqv7TjgNKpM"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDuRuytSNOkr"
      },
      "source": [
        "boston_housing=keras.datasets.boston_housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyjxahWSNOrX"
      },
      "source": [
        "(train_data,train_target),(test_data,test_target) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwqmyGosNOxq"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "\r\n",
        "# first we fit the scaler on the training dataset\r\n",
        "#scaler.fit(train_data)\r\n",
        "\r\n",
        "# then we call the transform method to scale both the training and testing data\r\n",
        "train_data_scaled = scaler.fit_transform(train_data)\r\n",
        "test_data_scaled = scaler.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kGJh4eYNO38"
      },
      "source": [
        "from keras import models, layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk7_C2uFNO_B"
      },
      "source": [
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(8, activation='relu', input_shape=[train_data.shape[1]]))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "\r\n",
        "\r\n",
        "# output layer\r\n",
        "model.add(layers.Dense(1))\r\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\r\n",
        "history = model.fit(train_data_scaled, train_target, validation_split=0.2, epochs=200)\r\n",
        "model.evaluate(test_data_scaled, test_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRL4IQiCSSW3"
      },
      "source": [
        "# we get a sample data (the first 2 inputs from the training data)\r\n",
        "to_predict = train_data_scaled[:2]\r\n",
        "# we call the predict method\r\n",
        "predictions = model.predict(to_predict)\r\n",
        "# print the predictions\r\n",
        "print(predictions)\r\n",
        "# output\r\n",
        "# array([[13.272537], [39.808475]], dtype=float32)\r\n",
        "# print the real values\r\n",
        "print(test_data[:2])\r\n",
        "## array([15.2, 42.3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHnYAPvaQnU4"
      },
      "source": [
        "#implementation using keras-tuner\r\n",
        "\"\"\"!pip install keras-tuner\r\n",
        "from kerastuner.tuners import RandomSearch\r\n",
        "\r\n",
        "def build_model(hp):\r\n",
        "    model = keras.Sequential()\r\n",
        "    for i in range(hp.Int('num_layers', 2, 5)):\r\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\r\n",
        "                                            min_value=2,\r\n",
        "                                            max_value=64,\r\n",
        "                                            step=32),\r\n",
        "                               activation='relu',\r\n",
        "                               ))\r\n",
        "\r\n",
        "    model.add(layers.Dense(1, activation='linear'))\r\n",
        "    model.compile(\r\n",
        "        optimizer=keras.optimizers.Adam(\r\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\r\n",
        "        loss='mean_absolute_error',\r\n",
        "        metrics=['mean_absolute_error'])\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "    \r\n",
        "tuner = RandomSearch(\r\n",
        "    build_model,\r\n",
        "    objective='val_mean_absolute_error',\r\n",
        "    max_trials=5,\r\n",
        "    executions_per_trial=3,\r\n",
        "    directory='output',\r\n",
        "    project_name='Air Quality Index')\r\n",
        "\r\n",
        "tuner.search_space_summary()\r\n",
        "tuner.search(train_data_scaled, train_target,\r\n",
        "             epochs=5,\r\n",
        "             validation_data=(test_data_scaled, test_target))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K-UeGzAPlTl"
      },
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhJ_kl9HPp0h"
      },
      "source": [
        "tuner.get_best_models(num_models=1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L07FH4f1P5sa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RAPN54tQFDH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}